{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for Twitter API\n",
    "ACCESS_TOKEN = '917808967274741762-r8YbHiXfNrUXJXn1dubUchtWrOZ2DMk'\n",
    "ACCESS_TOKEN_SECRET = 'jWo0gkDV5VGzaBkDeAkYc1e3dzf4D7N5IpuV6QdjR9x5E'\n",
    "CONSUMER_API_KEY = 'QaEAZ16UhHcc33CiZ6y8b672n'\n",
    "CONSUMER_API_SECRET = 'EIwXgXYGFBYZbMqTt22byRnQiQuUfWKqxbM03KKCiCTXiE8tVA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requred libraries\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and authentication object\n",
    "auth = tw.OAuthHandler(CONSUMER_API_KEY, CONSUMER_API_SECRET)\n",
    "\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# Create the API object passing the auth object\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the API object, get tweets from your timeline and store into a variable called, my_tweets\n",
    "my_tweets = api.home_timeline()\n",
    "\n",
    "# print(my_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @nkmk_me: #PythonË±ÜÁü•Ë≠ò\n",
      "\n",
      "Python„Å´„ÅØÁÑ°ÈôêÂ§ß„ÇíË°®„Åô„Äåinf„Äç„Åå„ÅÇ„Çã„ÄÇ„Äåfloat('inf')„Äç„Å™„Å©„ÅßÁîüÊàê„Åô„Çã„ÄÇ\n",
      "\n",
      "„Äåinf„Äç„ÅØÊµÆÂãïÂ∞èÊï∞ÁÇπÊï∞floatÂûã„Å†„Åå„ÄÅÊï¥Êï∞intÂûã„Å®„ÇÇÊØîËºÉÂèØËÉΩ„ÄÇ„Å©„ÅÆfloat„ÇÑint„ÅÆÂÄ§„Çà„Çä„ÇÇÂ§ß„Åç„ÅÑ„ÄÇ\n",
      "\n",
      "ÁÑ°ÈôêÂ§ß„Å´ÁÑ°ÈôêÂ§ß„ÇíÂä†„Åà„Å¶‚Ä¶\n",
      "2021-02-19 03:30:07 \n",
      " nkmk_me \n",
      "  \n",
      "\n",
      "RT @MayaRaghunandan: Our all-female-led story in @embojournal talks of #genomestability and #DDR at #ALTtelomeres: 2 topics I've been obses‚Ä¶\n",
      "2021-02-18 20:48:41 \n",
      " GS_Lab_Bham \n",
      "  \n",
      "\n",
      "RT @ShorterLab: cGAS phase separation inhibits TREX1-mediated DNA degradation and enhances cytosolic DNA sensing: https://t.co/Qv7yfYPFSX\n",
      "2021-02-18 20:41:37 \n",
      " GS_Lab_Bham \n",
      "  \n",
      "\n",
      "RT @JohnDoench: New work from the group published today, led by the incredible, integral, and incomparable @ruth_e_hanna, developing CRISPR‚Ä¶\n",
      "2021-02-18 20:40:35 \n",
      " GS_Lab_Bham \n",
      "  \n",
      "\n",
      "RT @CicciaAlberto: Interested in studying nucleotide variants on a high-throughput scale? Check out our recent work in @CellCellPress led b‚Ä¶\n",
      "2021-02-18 20:06:38 \n",
      " GS_Lab_Bham \n",
      "  \n",
      "\n",
      "RT @NatMetabolism: Online now! Diet-dependent regulation of TGFŒ≤ impairs reparative innate immune responses after demyelination https://t.c‚Ä¶\n",
      "2021-02-18 20:02:54 \n",
      " rochaandreal \n",
      " La Jolla, San Diego \n",
      "\n",
      "Clinically relevant mutations in core metabolic genes confer antibiotic resistance https://t.co/40TEdQtNjh\n",
      "2021-02-18 20:01:00 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "Mechanism of membrane-tethered mitochondrial protein synthesis https://t.co/F7pwNpRcW8\n",
      "2021-02-18 20:00:08 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "Mentor as you'd want to be mentored https://t.co/O8o2OIAPYn\n",
      "2021-02-18 19:51:29 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @ChemBioGlasgow: Not our usual organelle, but branching out: targeting the lysosome with lipophilic anions anyone?https://t.co/kpwn7Bj9CB\n",
      "2021-02-18 16:57:00 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @AntebiLab: One more week to apply! This is an open call for postdocs interested in joining our lab! https://t.co/nZGwfDnBXq\n",
      "2021-02-18 16:56:15 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @darissambaya: Check out this opportunity for a postdoc position in the Antebi lab at the Max Planck Institute for Biology of Ageing. ht‚Ä¶\n",
      "2021-02-18 16:55:19 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @tuuliel_lab: We're looking for a new faculty colleague at the New York Genome Center! We welcome applications in all areas of human gen‚Ä¶\n",
      "2021-02-18 16:55:11 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @NatRevNeph: Epigenetic mechanisms of metabolic memory in hyperglycaemia https://t.co/0YasCox9zi #DiabeticKidneyDisease https://t.co/XmO‚Ä¶\n",
      "2021-02-18 16:54:54 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @swiss_aging: Wonderful session @LS2Switzerland. Thx for the nice mentioning of the Swiss Society for Aging Research https://t.co/5nHV32‚Ä¶\n",
      "2021-02-18 16:28:18 \n",
      " CollinEwald \n",
      " Switzerland \n",
      "\n",
      "Reduced neutralization of SARS-CoV-2 B.1.1.7 variant by convalescent and vaccine sera https://t.co/FkUqsoJCMf\n",
      "2021-02-18 16:22:50 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "A time to build and a time to burn: glucose metabolism for every season https://t.co/tkx53NMi4G\n",
      "2021-02-18 16:21:01 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "Interferon-Œ≥ induces tumor resistance to anti-PD-1 immunotherapy by promoting YAP phase separation https://t.co/82LU2Xo4Td\n",
      "2021-02-18 16:19:38 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "Development of a colorimetric Œ±-ketoglutarate detection assay for prolyl hydroxylase domain (PHD) proteins https://t.co/ZpcS4LO3L0\n",
      "2021-02-18 16:16:55 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n",
      "RT @CellPressNews: Senescent Cells in Cancer Therapy: Friends or Foes? @Demarialab1, @ERIBA, @JaskarenKohli @trendscancer https://t.co/QxA4‚Ä¶\n",
      "2021-02-18 15:36:34 \n",
      " FrezzaLab \n",
      " Cambridge, England \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check all the pulled tweets in a frendly format\n",
    "for tweet in my_tweets:\n",
    "    print(tweet.text)\n",
    "    print(tweet.created_at, '\\n', tweet.user.screen_name, '\\n', tweet.user.location, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for 10 most recent tweets about \"#nlproc\"\n",
    "tweets = tw.Cursor(api.search, q='#wuhan', count=10, lang='en').items(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darlene Elizabeth Gagnon:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "JESUS IS COMING SOON:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Citizen:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Hard Right:JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renown‚Ä¶ https://t.co/5pghXZwXOg\n",
      "Joe And Kamala Lie:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "LondonAnonymous:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "1830:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "PlatosCaveman:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "A. Stoot:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Jonathan Aaron Steel:JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renown‚Ä¶ https://t.co/6klj50cQxj\n",
      "Silence Do Good:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Ivo üá≠üá∑ ‚ú†üöÄ:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Vlad:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "Old Man Mir:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n",
      "AceboogieBandz:RT @disclosetv: JUST IN - \"Corona came from a laboratory in #Wuhan,\" says Prof. Dr. Dr. h.c. Prof. h.c. Roland Wiesendanger, renowned physi‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "for tweet in api.search(q=\"#wuhan\", lang=\"en\", rpp=10):\n",
    "    print(f\"{tweet.user.name}:{tweet.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tweepy.Cursor(api.search,  \n",
    "\n",
    "              q=\"Giraffes\",\n",
    "              \n",
    "              since=\"2015-10-10\", \n",
    "              \n",
    "              until=\"2015-10-11\",\n",
    "              \n",
    "              count=100).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cursor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miles Costello said: Tempus is on IWG and Abcam\n",
      "https://t.co/CynbFiO3mg\n",
      "Chaser52 said: RT @smallcappick: The Times (Tempus share tips): HOLD #IWG; AVOID #Abcam. #ABC https://t.co/XXDVPkmmGz\n",
      "Australian Epigenetics Alliance said: A huge thanks again to our sponsors and to our attendees for visiting their booths. \n",
      "\n",
      "The #AsuEpi21 Gather Lottery‚Ä¶ https://t.co/su21UvGk0I\n",
      "TOP AIM STOCKS said: The Times (Tempus share tips): HOLD #IWG; AVOID #Abcam. #ABC https://t.co/XXDVPkmmGz\n",
      "Abcam ANZ said: InstantBlue¬Æ is a ready to use Coomassie protein stain for polyacrylamide gels. Add a free sample to your order thi‚Ä¶ https://t.co/0xLFv0DwzQ\n",
      "Australian Epigenetics Alliance said: RT @AbcamAnz: Dive deep into the complex interactions between Polycomb and Trithorax group proteins, including EZH2 and SMARCA4, and unders‚Ä¶\n",
      "Abcam ANZ said: RT @AEpiA: Lots of scientists all over Australia are enjoying actual #AusEpi21 conference dinner with real people and real food!\n",
      "Thanks to‚Ä¶\n",
      "Abcam ANZ said: Dive deep into the complex interactions between Polycomb and Trithorax group proteins, including EZH2 and SMARCA4,‚Ä¶ https://t.co/IzN3THxgde\n",
      "@LADYDAY93 in TJ said: RT @abcam: Thank you Mari Mino-Kenudson, @GCPrendergast, @BizarMd and R√ºdiger Greinert for the stimulating talks today. Don‚Äôt miss our last‚Ä¶\n",
      "PharmiWeb Jobs said: Research Associate-CLG - Hangzhou - Abcam #jobs #pharma #hiringnow #pharmiweb https://t.co/XPIw4ssBoM\n"
     ]
    }
   ],
   "source": [
    "for tweet in tw.Cursor(api.search, q='abcam', count=10, lang='en').items(10):\n",
    "    print(f\"{tweet.user.name} said: {tweet.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A huge thanks again to our sponsors and to our attendees for visiting their booths. \\n\\nThe #AsuEpi21 Gather Lottery‚Ä¶ https://t.co/su21UvGk0I'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = []\n",
    "for tweet in tw.Cursor(api.search, q='abcam', count=10, lang='en').items(10):\n",
    "    tweet_text.append(tweet.text)\n",
    "\n",
    "tweet_text[2]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_tweet = pd.DataFrame(tweet_text, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempus is on IWG and Abcam\\nhttps://t.co/CynbF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @smallcappick: The Times (Tempus share tips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A huge thanks again to our sponsors and to our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Tempus is on IWG and Abcam\\nhttps://t.co/CynbF...\n",
       "1  RT @smallcappick: The Times (Tempus share tips...\n",
       "2  A huge thanks again to our sponsors and to our..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempus is on IWG and Abcam\\nhttps://t.co/CynbF...</td>\n",
       "      <td>[tempus, iwg, abcam, httpstcocynbfio3mg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @smallcappick: The Times (Tempus share tips...</td>\n",
       "      <td>[rt, smallcappick, times, tempus, share, tips,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A huge thanks again to our sponsors and to our...</td>\n",
       "      <td>[huge, thanks, sponsors, attendees, visiting, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Times (Tempus share tips): HOLD #IWG; AVOI...</td>\n",
       "      <td>[times, tempus, share, tips, hold, iwg, avoid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InstantBlue¬Æ is a ready to use Coomassie prote...</td>\n",
       "      <td>[instantblue, ready, use, coomassie, protein, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Tempus is on IWG and Abcam\\nhttps://t.co/CynbF...   \n",
       "1  RT @smallcappick: The Times (Tempus share tips...   \n",
       "2  A huge thanks again to our sponsors and to our...   \n",
       "3  The Times (Tempus share tips): HOLD #IWG; AVOI...   \n",
       "4  InstantBlue¬Æ is a ready to use Coomassie prote...   \n",
       "\n",
       "                                          clean_text  \n",
       "0           [tempus, iwg, abcam, httpstcocynbfio3mg]  \n",
       "1  [rt, smallcappick, times, tempus, share, tips,...  \n",
       "2  [huge, thanks, sponsors, attendees, visiting, ...  \n",
       "3  [times, tempus, share, tips, hold, iwg, avoid,...  \n",
       "4  [instantblue, ready, use, coomassie, protein, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in and clean data\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "df_tweet['clean_text'] = df_tweet['text'].apply(lambda x: clean_text(x))\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv('retrieved_tweet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
